{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jgallear/CSSP_brazil_23_24/blob/main/forecast_all_simple_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QYB0Q-QbC0RA"
      },
      "outputs": [],
      "source": [
        "# Forecast across brazil but use harvested area threshold to filter out grid cells below 75th percentile of harvested area\n",
        "!pip install cartopy\n",
        "!pip install rioxarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kobajbrAC9UI"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import mapping\n",
        "import cartopy.crs as ccrs\n",
        "from cartopy.feature import ShapelyFeature\n",
        "from cartopy.io.shapereader import Reader\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "from shapely.geometry import Point\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from scipy.stats import pearsonr\n",
        "from cartopy.feature import ShapelyFeature\n",
        "from cartopy.io.shapereader import Reader\n",
        "from rasterio import CRS\n",
        "from shapely.geometry import mapping\n",
        "import xarray as xr\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from keras import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import functools\n",
        "import pickle\n",
        "import cartopy.feature as cf\n",
        "from scipy.stats import pearsonr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LrfQC_ygC_w2"
      },
      "outputs": [],
      "source": [
        "# load VHI and weather data table\n",
        "df = pd.read_csv('/content/drive/MyDrive/rs_data/VHI_merged_weather_data.csv')\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-BeD0dcZDCpc"
      },
      "outputs": [],
      "source": [
        "# load SPEI 1 and 3 data\n",
        "spei_1df = pd.read_csv('/content/drive/MyDrive/rs_data/SPEI/brazil_spei_025.csv')\n",
        "spei_2df = pd.read_csv('/content/drive/MyDrive/rs_data/SPEI/brazil_2m_spei_025.csv')\n",
        "spei_3df = pd.read_csv('/content/drive/MyDrive/rs_data/SPEI/brazil_3m_spei_025.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "To3Fssg7DE5v"
      },
      "outputs": [],
      "source": [
        "spei_1df.drop(columns='time',inplace=True)\n",
        "spei_3df.drop(columns='time',inplace=True)\n",
        "spei_2df.drop(columns='time',inplace=True)\n",
        "spei_1df.rename(columns={'spei':'spei1m'},inplace=True)\n",
        "spei_2df.rename(columns={'spei':'spei2m'},inplace=True)\n",
        "spei_3df.rename(columns={'spei':'spei3m'},inplace=True)\n",
        "\n",
        "spei_dfs = [spei_1df,spei_2df,spei_3df]\n",
        "spei_df = functools.reduce(lambda left, right: pd.merge(left, right, on=['lat','lon','year','month']), spei_dfs)\n",
        "\n",
        "#spei_df = spei_1df.merge(spei_3df,on=['lat','lon','year','month'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k76GTZVaKGzS"
      },
      "outputs": [],
      "source": [
        "df = df.merge(spei_df,on=['lon','lat','year','month'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Kro8LEBKc8m_"
      },
      "outputs": [],
      "source": [
        "# Need to add SPI and era5 data to df\n",
        "e5_longrad = pd.read_csv('/content/drive/MyDrive/rs_data/era5/regridded_era5_longrad.csv')\n",
        "e5_t2m = pd.read_csv('/content/drive/MyDrive/rs_data/era5/regridded_era5_2m_temperature.csv')\n",
        "e5_pev = pd.read_csv('/content/drive/MyDrive/rs_data/era5/regridded_era5_pot_evap.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "brGugC24Az2G"
      },
      "outputs": [],
      "source": [
        "print(e5_pev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HEWxnDPP8wrZ"
      },
      "outputs": [],
      "source": [
        "e5_longrad.drop(columns=['VHI','Unnamed: 0','precip','rtzsm_inst'],inplace=True)\n",
        "e5_t2m.drop(columns=['VHI','Unnamed: 0','precip','rtzsm_inst','msdwlwrf','pev'],inplace=True)\n",
        "e5_pev.drop(columns=['VHI','Unnamed: 0','precip','rtzsm_inst','msdwlwrf'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vdtMmcjXBl2d"
      },
      "outputs": [],
      "source": [
        "print(e5_longrad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BxHgb1ZcBl8L"
      },
      "outputs": [],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "13_5lVy191H6"
      },
      "outputs": [],
      "source": [
        "# merge to create era5 df\n",
        "era5_dfs = [e5_longrad,e5_t2m,e5_pev]\n",
        "e5_df_final = functools.reduce(lambda left, right: pd.merge(left, right, on=['lat','lon','year','month']), era5_dfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5klWMUKmAP_P"
      },
      "outputs": [],
      "source": [
        "df = df.merge(e5_df_final,on=['lon','lat','year','month'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gfsHa39JAcW2"
      },
      "outputs": [],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RhqG2bc9CgWc"
      },
      "outputs": [],
      "source": [
        "# add spi1-3 to the dataframe\n",
        "spi01 = pd.read_csv('/content/drive/MyDrive/rs_data/spi_gpcc/spi01_regridded_025.csv')\n",
        "spi02 = pd.read_csv('/content/drive/MyDrive/rs_data/spi_gpcc/spi02_regridded_025.csv')\n",
        "spi03 = pd.read_csv('/content/drive/MyDrive/rs_data/spi_gpcc/spi03_regridded_025.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9_8GSa0ADT8a"
      },
      "outputs": [],
      "source": [
        "print(spi03)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Is0Vq0ffDejk"
      },
      "outputs": [],
      "source": [
        "# spi03 contains everything so use that\n",
        "spi03.drop(columns=['VHI','precip','rtzsm_inst'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oFurzuMLD-iC"
      },
      "outputs": [],
      "source": [
        "df = df.merge(spi03,on=['lon','lat','year','month'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "85pJG_eSED3w"
      },
      "outputs": [],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MvdGkA5OLIbe"
      },
      "outputs": [],
      "source": [
        "def groupby_gc(df):\n",
        "  df_list=[]\n",
        "  for index,df in df.groupby(['lat','lon']):\n",
        "    df_list.append(df)\n",
        "  return df_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MHFs34L7L6Oe"
      },
      "outputs": [],
      "source": [
        "# create a function to match variable with previous month\n",
        "### This will be a Figure for the paper\n",
        "def match_months(df,var_name='VHI',months_prev=1):\n",
        "  # match each month with previus month(s) to find correlation between them\n",
        "  # first need to split into list of dfs based on grid cell location\n",
        "  # also need to create an if statement to only do if -1 is above February 2003\n",
        "  # append nan for this case\n",
        "  # and need to create an if statement for Jan 2004-2021 which gets December the previous year instead\n",
        "  # dont need to do this as already accounted for in df ordering\n",
        "  df_list = groupby_gc(df)\n",
        "  #print(df_list[0])\n",
        "  dfi_list=[]\n",
        "  for i in range(len(df_list)):\n",
        "    dfi = df_list[i]\n",
        "    dfi.reset_index(inplace=True)\n",
        "    dims = dfi.shape\n",
        "    #print(dfi.shape)\n",
        "    pm_var_list=[]\n",
        "    #print(dfi)\n",
        "    for j in np.arange(dims[0]):\n",
        "      if var_name == 'VHI':\n",
        "        if j >= months_prev:\n",
        "          pm_var_list.append(dfi.iloc[j-months_prev,3])\n",
        "        else:\n",
        "           pm_var_list.append(np.nan)\n",
        "      elif var_name == 'precip':\n",
        "        if j >= months_prev:\n",
        "          pm_var_list.append(dfi.iloc[j-months_prev,6])\n",
        "        else:\n",
        "           pm_var_list.append(np.nan)\n",
        "      elif var_name == 'rtzsm_inst':\n",
        "        if j >= months_prev:\n",
        "          pm_var_list.append(dfi.iloc[j-months_prev,7])\n",
        "        else:\n",
        "           pm_var_list.append(np.nan)\n",
        "      elif var_name == 'spei1m':\n",
        "        if j >= months_prev:\n",
        "          pm_var_list.append(dfi.iloc[j-months_prev,8])\n",
        "        else:\n",
        "           pm_var_list.append(np.nan)\n",
        "      elif var_name == 'spei2m':\n",
        "        if j >= months_prev:\n",
        "          pm_var_list.append(dfi.iloc[j-months_prev,9])\n",
        "        else:\n",
        "           pm_var_list.append(np.nan)\n",
        "      elif var_name == 'spei3m':\n",
        "        if j >= months_prev:\n",
        "          pm_var_list.append(dfi.iloc[j-months_prev,10])\n",
        "        else:\n",
        "           pm_var_list.append(np.nan)\n",
        "      elif var_name == 'msdwlwrf':\n",
        "        if j >= months_prev:\n",
        "          pm_var_list.append(dfi.iloc[j-months_prev,11])\n",
        "        else:\n",
        "          pm_var_list.append(np.nan)\n",
        "      elif var_name == 't2m':\n",
        "        if j >= months_prev:\n",
        "          pm_var_list.append(dfi.iloc[j-months_prev,12])\n",
        "        else:\n",
        "          pm_var_list.append(np.nan)\n",
        "      elif var_name == 'pev':\n",
        "        if j >= months_prev:\n",
        "          pm_var_list.append(dfi.iloc[j-months_prev,13])\n",
        "        else:\n",
        "          pm_var_list.append(np.nan)\n",
        "      elif var_name == 'spi_01':\n",
        "        if j >= months_prev:\n",
        "          pm_var_list.append(dfi.iloc[j-months_prev,14])\n",
        "        else:\n",
        "          pm_var_list.append(np.nan)\n",
        "      elif var_name == 'spi_02':\n",
        "        if j >= months_prev:\n",
        "          pm_var_list.append(dfi.iloc[j-months_prev,15])\n",
        "        else:\n",
        "          pm_var_list.append(np.nan)\n",
        "      elif var_name == 'spi_03':\n",
        "        if j >= months_prev:\n",
        "          pm_var_list.append(dfi.iloc[j-months_prev,16])\n",
        "        else:\n",
        "           pm_var_list.append(np.nan)\n",
        "    #print(pm_var_list)\n",
        "    print(len(pm_var_list))\n",
        "    dfi[var_name+str(-months_prev)] = pm_var_list\n",
        "    #print(dfi)\n",
        "    dfi_list.append(dfi)\n",
        "  return pd.concat(dfi_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O0S6Qb_6MSU1"
      },
      "outputs": [],
      "source": [
        "def load_p_file(fname):\n",
        "  with open(fname,'rb') as input_file:\n",
        "    e = pickle.load(input_file)\n",
        "  return e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "utXGqu3ZMdrp"
      },
      "outputs": [],
      "source": [
        "# load harvest area filtered by state\n",
        "mai_ar_state = load_p_file('/content/drive/MyDrive/area_data/crop_grids/mai_harvest_area_by_state.pickle')\n",
        "soy_ar_state = load_p_file('/content/drive/MyDrive/area_data/crop_grids/soy_harvest_area_by_state.pickle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OnX_jXeaMjLm"
      },
      "outputs": [],
      "source": [
        "# Need to rename x and y to lat and lon\n",
        "soy_ar_state = soy_ar_state.rename(columns={'x':'lon','y':'lat'})\n",
        "mai_ar_state = mai_ar_state.rename(columns={'x':'lon','y':'lat'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lbSsQ67fM7uZ"
      },
      "outputs": [],
      "source": [
        "soy_ar_state = soy_ar_state[soy_ar_state['harvarea']>0]\n",
        "soy_threshold = np.percentile(soy_ar_state['harvarea'],75)\n",
        "soy_area_high_ha = soy_ar_state[soy_ar_state['harvarea'] >= soy_threshold]\n",
        "###\n",
        "mai_ar_state = mai_ar_state[mai_ar_state['harvarea']>0]\n",
        "mai_threshold = np.percentile(mai_ar_state['harvarea'],75)\n",
        "mai_area_high_ha = mai_ar_state[mai_ar_state['harvarea'] >= mai_threshold]\n",
        "###\n",
        "high_ha_soy_coords = soy_area_high_ha.drop(columns=['geometry','croparea','qual','set','index_right','UF'])\n",
        "high_ha_mai_coords = mai_area_high_ha.drop(columns=['geometry','croparea','qual','set','index_right','UF'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "af2vLZeBcf0A"
      },
      "outputs": [],
      "source": [
        "print(high_ha_soy_coords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bezoRSsJcuDR"
      },
      "outputs": [],
      "source": [
        "def match_harvest_areas(df, coords_df):\n",
        "  # need to put data into per year list before matching\n",
        "  # harvarea dataframe\n",
        "  df_list = groupby_gc(df)\n",
        "  # use df.merge to apply coordinates to each df\n",
        "  merged_df_list=[]\n",
        "  for i in range(len(df_list)):\n",
        "    merged_df_list.append(df_list[i].merge(coords_df,on=['lat','lon']))\n",
        "  merged_df = pd.concat(merged_df_list)\n",
        "  return merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "utxvI1hTgNlD"
      },
      "outputs": [],
      "source": [
        "df_soy = match_harvest_areas(df,high_ha_soy_coords)\n",
        "df_mai = match_harvest_areas(df,high_ha_mai_coords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R56E8YbsSzCF"
      },
      "outputs": [],
      "source": [
        "print(df_mai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mmFQM1pGS19m"
      },
      "outputs": [],
      "source": [
        "# combine 75% soy and maize - then later cluster based on ccoef relationship with vhi\n",
        "df_crops = pd.concat([df_mai,df_soy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nRsbbR2lTzGs"
      },
      "outputs": [],
      "source": [
        "def per_gc_metrics(df):\n",
        "  m1_df_anom_gc_list = groupby_gc(df)\n",
        "  lat_list=[]\n",
        "  lon_list=[]\n",
        "  vhi_averages=[]\n",
        "  vhi_spei3_ccoefs=[]\n",
        "  vhi_rzsm_ccoefs=[]\n",
        "  vhi_precip_ccoefs=[]\n",
        "  for i in range(len(m1_df_anom_gc_list)):\n",
        "    # get average vhi and plot\n",
        "    vhi_averages.append(np.mean(m1_df_anom_gc_list[i]['VHI']))\n",
        "    vhi_spei3_ccoefs.append(pearsonr(m1_df_anom_gc_list[i]['VHI'],m1_df_anom_gc_list[i]['spei3m'])[0])\n",
        "    vhi_rzsm_ccoefs.append(pearsonr(m1_df_anom_gc_list[i]['VHI'],m1_df_anom_gc_list[i]['rtzsm_inst'])[0])\n",
        "    vhi_precip_ccoefs.append(pearsonr(m1_df_anom_gc_list[i]['VHI'],m1_df_anom_gc_list[i]['precip'])[0])\n",
        "    # get latitude and longitude coordinates\n",
        "    lat = m1_df_anom_gc_list[i]['lat'].values[0]\n",
        "    lat_list.append(lat)\n",
        "    lon = m1_df_anom_gc_list[i]['lon'].values[0]\n",
        "    lon_list.append(lon)\n",
        "  return lat_list, lon_list, vhi_averages, vhi_spei3_ccoefs, vhi_rzsm_ccoefs,vhi_precip_ccoefs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ciYBaP2LT3FK"
      },
      "outputs": [],
      "source": [
        "maize_lats, maize_lons, maize_vhi, maize_speiccoef, maize_rzsm_ccoef, vhi_precip_ccoef = per_gc_metrics(df_crops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2LSjkhlsVE9p"
      },
      "outputs": [],
      "source": [
        "# add shape feature\n",
        "# load Brazil shapefile\n",
        "fname = '/content/drive/MyDrive/shapefiles/BR/BR_EST_SAD69.shp'\n",
        "shape_feature = ShapelyFeature(Reader(fname).geometries(),\n",
        "                                ccrs.PlateCarree(), facecolor='none')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3jJ0Mb1UL9Cp"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10,12))\n",
        "ax1 = fig.add_subplot(1,1,1,projection=ccrs.PlateCarree())\n",
        "#ax1.coastlines()\n",
        "im=ax1.scatter(maize_lons, maize_lats, c=vhi_precip_ccoef, marker=',', transform=ccrs.PlateCarree(), cmap='Spectral',s=4)\n",
        "# # Set the location and size of the colorbar axes manually\n",
        "#cax = fig.add_axes([]) # left, bottom, width, height\n",
        "# # Add the colorbar\n",
        "divider = make_axes_locatable(ax1)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05,axes_class=plt.Axes)\n",
        "cbar = fig.colorbar(im, ax=ax1,cax=cax)\n",
        "cbar.ax.set_ylabel('correlation coefficient',fontsize='14')\n",
        "ax1.title.set_text('correlation between rainfall and vhi')\n",
        "ax1.set_extent([-80, -30, -40, 10], crs=ccrs.PlateCarree())\n",
        "#plt.savefig('plots/Iizumi_2020_maize_global.pdf')\n",
        "#ax1.add_feature(cf.BORDERS)\n",
        "ax1.add_feature(shape_feature)\n",
        "ax1.add_feature(cf.LAND)\n",
        "ax1.add_feature(cf.OCEAN)\n",
        "ax1.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5dJOocRVL9ME"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cbOU81OtUXpm"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10,12))\n",
        "ax1 = fig.add_subplot(1,1,1,projection=ccrs.PlateCarree())\n",
        "#ax1.coastlines()\n",
        "im=ax1.scatter(maize_lons, maize_lats, c=maize_speiccoef, marker=',', transform=ccrs.PlateCarree(), cmap='Spectral',s=4)\n",
        "# # Set the location and size of the colorbar axes manually\n",
        "#cax = fig.add_axes([]) # left, bottom, width, height\n",
        "# # Add the colorbar\n",
        "divider = make_axes_locatable(ax1)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05,axes_class=plt.Axes)\n",
        "cbar = fig.colorbar(im, ax=ax1,cax=cax)\n",
        "cbar.ax.set_ylabel('correlation coefficient',fontsize='14')\n",
        "ax1.title.set_text('correlation between spei and vhi')\n",
        "ax1.set_extent([-80, -30, -40, 10], crs=ccrs.PlateCarree())\n",
        "#plt.savefig('plots/Iizumi_2020_maize_global.pdf')\n",
        "#ax1.add_feature(cf.BORDERS)\n",
        "ax1.add_feature(shape_feature)\n",
        "ax1.add_feature(cf.LAND)\n",
        "ax1.add_feature(cf.OCEAN)\n",
        "ax1.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cRIgwO7FUs2S"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10,12))\n",
        "ax1 = fig.add_subplot(1,1,1,projection=ccrs.PlateCarree())\n",
        "#ax1.coastlines()\n",
        "im=ax1.scatter(maize_lons, maize_lats, c=maize_rzsm_ccoef, marker=',', transform=ccrs.PlateCarree(), cmap='Spectral')\n",
        "# # Set the location and size of the colorbar axes manually\n",
        "#cax = fig.add_axes([]) # left, bottom, width, height\n",
        "# # Add the colorbar\n",
        "divider = make_axes_locatable(ax1)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05,axes_class=plt.Axes)\n",
        "cbar = fig.colorbar(im, ax=ax1,cax=cax)\n",
        "cbar.ax.set_ylabel('correlation coefficient',fontsize='14')\n",
        "ax1.title.set_text('correlation between rzsm and vhi')\n",
        "ax1.set_extent([-80, -30, -40, 10], crs=ccrs.PlateCarree())\n",
        "#plt.savefig('plots/Iizumi_2020_maize_global.pdf')\n",
        "#ax1.add_feature(cf.BORDERS)\n",
        "ax1.add_feature(shape_feature)\n",
        "ax1.add_feature(cf.LAND)\n",
        "ax1.add_feature(cf.OCEAN)\n",
        "ax1.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MnP8zq76NS3d"
      },
      "outputs": [],
      "source": [
        "def combine_dims(a, i=0, n=1):\n",
        "  \"\"\"\n",
        "  Combines dimensions of numpy array 'a',\n",
        "  starting at index 'i',\n",
        "  and combining 'n' dimensions\n",
        "  \"\"\"\n",
        "  s = list(a.shape)\n",
        "  combined = functools.reduce(lambda x,y: x*y, s[i:i+n+1])\n",
        "  return np.reshape(a, s[:i] + [combined] + s[i+n+1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tjNebYSPLp5s"
      },
      "outputs": [],
      "source": [
        "# Need to filter df by high harvest area coords\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tECgV3xLNUB9"
      },
      "outputs": [],
      "source": [
        "vhi_df = match_months(df_crops,var_name='VHI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hQArOUEii1Dx"
      },
      "outputs": [],
      "source": [
        "print(df_crops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "puV3ADfLx1QR"
      },
      "outputs": [],
      "source": [
        "df_crops.to_csv('/content/drive/MyDrive/rs_data/merged_dataframe.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0s3HTNbmioIQ"
      },
      "outputs": [],
      "source": [
        "rzsm_crops_df = match_months(df_crops,var_name='rtzsm_inst')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7vYmh1YZf7gp"
      },
      "outputs": [],
      "source": [
        "print(vhi_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B1dHYbJAf7pY"
      },
      "outputs": [],
      "source": [
        "# drop nan values\n",
        "vhi_df.dropna(inplace=True)\n",
        "# predict VHI precip, rtzsm spei etc from previous month using range of methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9deszjYSJfPt"
      },
      "outputs": [],
      "source": [
        "# predict VHI from VHI-1\n",
        "# show error in predictions as RMSE map\n",
        "print(vhi_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BEUgjetzsXou"
      },
      "outputs": [],
      "source": [
        "# Do train / test split by year then predict VHI\n",
        "GBM_model = GradientBoostingRegressor(n_estimators = 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PVjgCEM1tRn-"
      },
      "outputs": [],
      "source": [
        "trainx = vhi_df[vhi_df['year']!=2021]['VHI-1'].values.reshape(-1,1)\n",
        "trainy = vhi_df[vhi_df['year']!=2021]['VHI'].values.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "F5tlu8jEttJn"
      },
      "outputs": [],
      "source": [
        "testx = vhi_df[vhi_df['year']==2021]['VHI-1'].values.reshape(-1,1)\n",
        "testy = vhi_df[vhi_df['year']==2021]['VHI'].values.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8Dm8YvCnxSJm"
      },
      "outputs": [],
      "source": [
        "test_lat = vhi_df[vhi_df['year']==2021]['lat'].values.reshape(-1,1)\n",
        "test_lon = vhi_df[vhi_df['year']==2021]['lon'].values.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tYSuf5yctySA"
      },
      "outputs": [],
      "source": [
        "# next fit model using training data\n",
        "GBM_model.fit(trainx,trainy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4krzm-SZuL1T"
      },
      "outputs": [],
      "source": [
        "GBM_predictions = GBM_model.predict(testx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B8gi1jb8w3hN"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zQBPaDo9w6Ub"
      },
      "outputs": [],
      "source": [
        "print(mean_absolute_error(testy,GBM_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Tw5HvkU8wWlQ"
      },
      "outputs": [],
      "source": [
        "line = np.arange(0,100,10)\n",
        "fig = plt.figure()\n",
        "plt.scatter(testy,GBM_predictions,color='green',alpha=0.4,s=6)\n",
        "plt.ylabel('predicted VHI %')\n",
        "plt.xlabel('observed VHI %')\n",
        "plt.title('GBM predictions')\n",
        "plt.plot(line,line,linestyle='--',color='k')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZUJXlaILOIJu"
      },
      "outputs": [],
      "source": [
        "#print(pearsonr(testy,GBM_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZpKfpnlizWmq"
      },
      "outputs": [],
      "source": [
        "print(test_lat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RQN-ALcPxIMw"
      },
      "outputs": [],
      "source": [
        "# plot predictions as map (average VHI for 2021)\n",
        "map_df=pd.DataFrame({'lat':combine_dims(test_lat),'lon':combine_dims(test_lon),'predictions':combine_dims(GBM_predictions),'observed':combine_dims(testy)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y30ekxgw0zpV"
      },
      "outputs": [],
      "source": [
        "def rmse(predictions, targets):\n",
        "    return ((np.sqrt(((predictions - targets) ** 2)).mean())/np.mean(targets))*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ydtAX3cb9bnQ"
      },
      "outputs": [],
      "source": [
        "def rmse(predictions, targets):\n",
        "    return np.sqrt(((predictions - targets) ** 2).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vuhApC_Yzttb"
      },
      "outputs": [],
      "source": [
        "def get_locationwise_av(df):\n",
        "  df_list = groupby_gc(df)\n",
        "  av_vhi_preds=[]\n",
        "  av_vhi_obs=[]\n",
        "  vhi_rmse=[]\n",
        "  lats=[]\n",
        "  lons=[]\n",
        "  for i in range(len(df_list)):\n",
        "    av_vhi_preds.append(np.mean(df_list[i]['predictions']))\n",
        "    av_vhi_obs.append(np.mean(df_list[i]['observed']))\n",
        "    vhi_rmse.append(rmse(df_list[i]['predictions'],df_list[i]['observed']))\n",
        "    lats.append(df_list[i]['lat'].values[0])\n",
        "    lons.append(df_list[i]['lon'].values[0])\n",
        "  return vhi_rmse,lats,lons, av_vhi_preds, av_vhi_obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EVHidK1l1Zh2"
      },
      "outputs": [],
      "source": [
        "vhi_rmse_map,map_lats,map_lons,preds,obs = get_locationwise_av(map_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pyXllkSY2enE"
      },
      "outputs": [],
      "source": [
        "# load Brazil shapefile\n",
        "fname = '/content/drive/MyDrive/shapefiles/BR/BR_EST_SAD69.shp'\n",
        "shape_feature = ShapelyFeature(Reader(fname).geometries(),\n",
        "                                ccrs.PlateCarree(), facecolor='none')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jm2mVT_j1tLm"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10,12))\n",
        "ax1 = fig.add_subplot(1,1,1,projection=ccrs.PlateCarree())\n",
        "#ax1.coastlines()\n",
        "im=ax1.scatter(map_lons, map_lats, c=vhi_rmse_map, marker=',', transform=ccrs.PlateCarree(), cmap='Spectral_r',s=4)\n",
        "# # Set the location and size of the colorbar axes manually\n",
        "#cax = fig.add_axes([]) # left, bottom, width, height\n",
        "# # Add the colorbar\n",
        "divider = make_axes_locatable(ax1)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05,axes_class=plt.Axes)\n",
        "cbar = fig.colorbar(im, ax=ax1,cax=cax)\n",
        "cbar.ax.set_ylabel('VHI(%) RMSE',fontsize='14')\n",
        "ax1.title.set_text('RMSE VHI predictions (all months 2021)')\n",
        "ax1.set_extent([-80, -30, -40, 10], crs=ccrs.PlateCarree())\n",
        "#plt.savefig('plots/Iizumi_2020_maize_global.pdf')\n",
        "#ax1.add_feature(cf.BORDERS)\n",
        "ax1.add_feature(shape_feature)\n",
        "ax1.add_feature(cf.LAND)\n",
        "ax1.add_feature(cf.OCEAN)\n",
        "ax1.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uhqeGqKC8XBP"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10,12))\n",
        "ax1 = fig.add_subplot(1,1,1,projection=ccrs.PlateCarree())\n",
        "#ax1.coastlines()\n",
        "im=ax1.scatter(map_lons, map_lats, c=preds, marker=',', transform=ccrs.PlateCarree(), cmap='Spectral',vmin=0,vmax=70)\n",
        "# # Set the location and size of the colorbar axes manually\n",
        "#cax = fig.add_axes([]) # left, bottom, width, height\n",
        "# # Add the colorbar\n",
        "divider = make_axes_locatable(ax1)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05,axes_class=plt.Axes)\n",
        "cbar = fig.colorbar(im, ax=ax1,cax=cax)\n",
        "cbar.ax.set_ylabel('Predicted VHI',fontsize='14')\n",
        "ax1.title.set_text('Average VHI predictions (2021)')\n",
        "ax1.set_extent([-80, -30, -40, 10], crs=ccrs.PlateCarree())\n",
        "#plt.savefig('plots/Iizumi_2020_maize_global.pdf')\n",
        "#ax1.add_feature(cf.BORDERS)\n",
        "ax1.add_feature(shape_feature)\n",
        "ax1.add_feature(cf.LAND)\n",
        "ax1.add_feature(cf.OCEAN)\n",
        "ax1.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VYWHCy4F8qtR"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10,12))\n",
        "ax1 = fig.add_subplot(1,1,1,projection=ccrs.PlateCarree())\n",
        "#ax1.coastlines()\n",
        "im=ax1.scatter(map_lons, map_lats, c=obs, marker=',', transform=ccrs.PlateCarree(), cmap='Spectral',vmin=0,vmax=70)\n",
        "# # Set the location and size of the colorbar axes manually\n",
        "#cax = fig.add_axes([]) # left, bottom, width, height\n",
        "# # Add the colorbar\n",
        "divider = make_axes_locatable(ax1)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05,axes_class=plt.Axes)\n",
        "cbar = fig.colorbar(im, ax=ax1,cax=cax)\n",
        "cbar.ax.set_ylabel('Predicted VHI',fontsize='14')\n",
        "ax1.title.set_text('Average observed VHI (2021)')\n",
        "ax1.set_extent([-80, -30, -40, 10], crs=ccrs.PlateCarree())\n",
        "#plt.savefig('plots/Iizumi_2020_maize_global.pdf')\n",
        "#ax1.add_feature(cf.BORDERS)\n",
        "ax1.add_feature(shape_feature)\n",
        "ax1.add_feature(cf.LAND)\n",
        "ax1.add_feature(cf.OCEAN)\n",
        "ax1.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Dxo6Cwjo69pV"
      },
      "outputs": [],
      "source": [
        "print(vhi_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9BCjABZzLHrw"
      },
      "outputs": [],
      "source": [
        "print(df_crops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RclG7zxzNswS",
        "outputId": "da6f090c-a38e-460f-c638-117339936f33"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df_crops' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f251c909d100>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_crops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/df_crops_full.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_crops' is not defined"
          ]
        }
      ],
      "source": [
        "df_crops.to_csv('/content/drive/MyDrive/df_crops_full.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UjjavaZ662PA"
      },
      "outputs": [],
      "source": [
        "vhi_df = match_months(df_crops,var_name='VHI')\n",
        "vhi_df.dropna(inplace=True)\n",
        "precip_df = match_months(df_crops,var_name='precip')\n",
        "precip_df.dropna(inplace=True)\n",
        "rzsm_df = match_months(df_crops,var_name='rtzsm_inst')\n",
        "rzsm_df.dropna(inplace=True)\n",
        "spei1_df = match_months(df_crops,var_name='spei1m')\n",
        "spei1_df.dropna(inplace=True)\n",
        "spei2_df = match_months(df_crops,var_name='spei2m')\n",
        "spei2_df.dropna(inplace=True)\n",
        "spei3_df = match_months(df_crops,var_name='spei3m')\n",
        "spei3_df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tHawDPuqNumV"
      },
      "outputs": [],
      "source": [
        "print(vhi_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iQcAeQGTLDho"
      },
      "outputs": [],
      "source": [
        "spi1_df = match_months(df_crops,var_name='spi_01')\n",
        "spi1_df.dropna(inplace=True)\n",
        "spi2_df = match_months(df_crops,var_name='spi_02')\n",
        "spi2_df.dropna(inplace=True)\n",
        "spi3_df = match_months(df_crops,var_name='spi_03')\n",
        "spi3_df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Xvf0lE1AMc3u"
      },
      "outputs": [],
      "source": [
        "# Get era5 data\n",
        "longrad_df = match_months(df_crops,var_name='msdwlwrf')\n",
        "longrad_df.dropna(inplace=True)\n",
        "pev_df = match_months(df_crops,var_name='pev')\n",
        "pev_df.dropna(inplace=True)\n",
        "t2m_df = match_months(df_crops,var_name='t2m')\n",
        "t2m_df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uU6p_xl5HSH0"
      },
      "outputs": [],
      "source": [
        "print(vhi_df['lon'].values.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7-66KBVEOKQ2"
      },
      "outputs": [],
      "source": [
        "print(spi1_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R7GQ1FXG8xUR"
      },
      "outputs": [],
      "source": [
        "# create prediction dataframe out of -1s and coordinates, year and month\n",
        "m1_df = pd.DataFrame({'lon':vhi_df['lon'].values,'lat':vhi_df['lat'].values,'vhi-1':vhi_df['VHI-1'].values,'precip-1':precip_df['precip-1'].values,'rzsm-1':rzsm_df['rtzsm_inst-1'].values,\n",
        "                      'spei1-1m':spei1_df['spei1m-1'].values,'spei2-1m':spei2_df['spei2m-1'].values,'spei3-1m':spei3_df['spei3m-1'].values,'spi01-1':spi1_df['spi_01-1'].values,'spi02-1':spi2_df['spi_02-1'].values,\n",
        "                      'spi03-1':spi3_df['spi_03-1'].values,'pev-1':pev_df['pev-1'].values,'longrad-1':longrad_df['msdwlwrf-1'].values,'t2m-1':t2m_df['t2m-1'].values,\n",
        "                      'month':vhi_df['month'].values,'year':vhi_df['year'].values,'VHI':vhi_df['VHI'].values})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a7sYHHBVJLba"
      },
      "outputs": [],
      "source": [
        "print(m1_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PY090kb_xndy"
      },
      "outputs": [],
      "source": [
        "#save m1_df dataframe\n",
        "m1_df.to_csv('/content/drive/MyDrive/VHI_spei_rzsm_dataset.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "anDlweOlJT6G"
      },
      "outputs": [],
      "source": [
        "# create xy train-test split\n",
        "# added meteorological data to model\n",
        "# 2021 is test year\n",
        "m1_df_test = m1_df[m1_df['year']==2021]\n",
        "m1_df_train = m1_df[m1_df['year']<2021]\n",
        "\n",
        "##\n",
        "trainx = m1_df_train.drop(columns=['VHI'])\n",
        "testx = m1_df_test.drop(columns=['VHI'])\n",
        "# trainy and testy\n",
        "trainy = m1_df_train['VHI']\n",
        "testy =  m1_df_test['VHI']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HQ4o1IhTL82V"
      },
      "outputs": [],
      "source": [
        "# Do train / test split by year then predict VHI\n",
        "GBM_model = GradientBoostingRegressor(n_estimators = 200)\n",
        "# fit GBM model to train and test\n",
        "# next fit model using training data\n",
        "GBM_model.fit(trainx,trainy) # model with vhi and spei precip and rzsm from previous month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GWVm8fduMsqj"
      },
      "outputs": [],
      "source": [
        "m_GBM_predictions = GBM_model.predict(testx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TFRTbv4BMQFC"
      },
      "outputs": [],
      "source": [
        "line = np.arange(0,100,10)\n",
        "fig = plt.figure()\n",
        "plt.scatter(testy,m_GBM_predictions,color='green',alpha=0.4,s=6)\n",
        "plt.ylabel('predicted VHI %')\n",
        "plt.xlabel('observed VHI %')\n",
        "plt.plot(line,line,linestyle='--',color='k')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UteI2rqoVxaS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ml3yjsHaV1D2"
      },
      "outputs": [],
      "source": [
        "print(mean_absolute_error(testy,m_GBM_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-HArhx0_NtvK"
      },
      "outputs": [],
      "source": [
        "print(pearsonr(testy,m_GBM_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k7TTNd6LQ7Rm"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "result_0 = permutation_importance(GBM_model,trainx,trainy,scoring='r2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kVW7KzJHRJfg"
      },
      "outputs": [],
      "source": [
        "gbm_importances = pd.Series(result_0.importances_mean, index=trainx.columns)\n",
        "fig, ax = plt.subplots()\n",
        "gbm_importances.plot.bar(yerr=result_0.importances_std, ax=ax)\n",
        "ax.set_title(\"GBM feature importances all data\")\n",
        "ax.set_ylabel(\"r2 score\")\n",
        "fig.tight_layout()\n",
        "plt.ylim(0,1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RYCTvcpVP6qt"
      },
      "outputs": [],
      "source": [
        "# Do permutation feature importance:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "V3wz0f6hOO6i"
      },
      "outputs": [],
      "source": [
        "# remove variables and check\n",
        "# 2021 is test year\n",
        "m1_df_test = m1_df[m1_df['year']==2021]\n",
        "m1_df_train = m1_df[m1_df['year']<2021]\n",
        "\n",
        "##\n",
        "trainx = m1_df_train.drop(columns=['VHI','vhi-1'])\n",
        "testx = m1_df_test.drop(columns=['VHI','vhi-1'])\n",
        "# trainy and testy\n",
        "trainy = m1_df_train['VHI']\n",
        "testy =  m1_df_test['VHI']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oU-His97PHtd"
      },
      "outputs": [],
      "source": [
        "# Do train / test split by year then predict VHI\n",
        "GBM_model = GradientBoostingRegressor(n_estimators = 200)\n",
        "# fit GBM model to train and test\n",
        "# next fit model using training data\n",
        "GBM_model.fit(trainx,trainy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lwUbABdQPaJs"
      },
      "outputs": [],
      "source": [
        "m_GBM_predictions = GBM_model.predict(testx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xmeEJPPJPNXu"
      },
      "outputs": [],
      "source": [
        "line = np.arange(0,100,10)\n",
        "fig = plt.figure()\n",
        "plt.scatter(testy,m_GBM_predictions,color='green',alpha=0.4,s=6)\n",
        "plt.ylabel('predicted VHI')\n",
        "plt.xlabel('observed VHI')\n",
        "plt.plot(line,line,linestyle='--',color='k')\n",
        "plt.show()\n",
        "print(pearsonr(testy,m_GBM_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "deAe_u13QGn6"
      },
      "outputs": [],
      "source": [
        "# Use GBM model to predict future months of SPEI3 and/or rzsm then add make model based on that\n",
        "m1_df = pd.DataFrame({'lon':vhi_df['lon'].values,'lat':vhi_df['lat'].values,'vhi-1':vhi_df['VHI-1'].values,'precip-1':precip_df['precip-1'].values,'rzsm-1':rzsm_df['rtzsm_inst-1'].values,'spei1-1m':spei1_df['spei1m-1'].values,'spei3-1m':spei3_df['spei3m-1'].values,'month':vhi_df['month'].values,'year':vhi_df['year'].values,'VHI':vhi_df['VHI'].values,'rzsm':rzsm_df['rtzsm_inst'].values})\n",
        "m1_df_test = m1_df[m1_df['year']==2021]\n",
        "m1_df_train = m1_df[m1_df['year']<2021]\n",
        "\n",
        "##\n",
        "trainx = m1_df_train.drop(columns=['VHI','vhi-1','rzsm'])\n",
        "testx = m1_df_test.drop(columns=['VHI','vhi-1','rzsm'])\n",
        "# trainy and testy\n",
        "trainy = m1_df_train['rzsm']\n",
        "testy =  m1_df_test['rzsm']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IR78iF5GRm-G"
      },
      "outputs": [],
      "source": [
        "# Do train / test split by year then predict VHI\n",
        "GBM_model = GradientBoostingRegressor(n_estimators = 200)\n",
        "# fit GBM model to train and test\n",
        "# next fit model using training data\n",
        "GBM_model.fit(trainx,trainy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BLqT4vwZR0pM"
      },
      "outputs": [],
      "source": [
        "m_GBM_predictions = GBM_model.predict(testx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uTKNSRkOSOkE"
      },
      "outputs": [],
      "source": [
        "line = np.arange(0,100,10)\n",
        "fig = plt.figure()\n",
        "plt.scatter(testy,m_GBM_predictions,color='green',alpha=0.4,s=6)\n",
        "plt.ylabel('predicted RZSM')\n",
        "plt.xlabel('observed RZSM')\n",
        "plt.plot(line,line,linestyle='--',color='k')\n",
        "plt.show()\n",
        "print(pearsonr(testy,m_GBM_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-ZfWtOaTWvP"
      },
      "source": [
        "Unpredicting RZSM is probably due to the downward trend in RZSM across the time period. to improve this should detrend RZSM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dqToitFrUgq1"
      },
      "outputs": [],
      "source": [
        "# detrend RZSM\n",
        "print(m1_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RNhxW2cAS-Lg"
      },
      "outputs": [],
      "source": [
        "# Is correlation between predicted RZSM and next months VHI better than VHI and previous months RZSM\n",
        "#line = np.arange(0,100,10)\n",
        "fig = plt.figure()\n",
        "plt.scatter(m1_df_test['VHI'],m_GBM_predictions,color='green',alpha=0.4,s=6)\n",
        "plt.ylabel('predicted RZSM')\n",
        "plt.xlabel('observed VHI')\n",
        "#plt.plot(line,line,linestyle='--',color='k')\n",
        "plt.show()\n",
        "print(pearsonr(m1_df_test['VHI'],m_GBM_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WrSUuxFmVK4T"
      },
      "outputs": [],
      "source": [
        "# how does it compare to previous months rzsm\n",
        "fig = plt.figure()\n",
        "plt.scatter(m1_df_test['VHI'],m1_df_test['rzsm-1'].values,color='green',alpha=0.4,s=6)\n",
        "plt.ylabel('RZSM-1')\n",
        "plt.xlabel('observed VHI')\n",
        "#plt.plot(line,line,linestyle='--',color='k')\n",
        "plt.show()\n",
        "print(pearsonr(m1_df_test['VHI'],m1_df_test['rzsm-1'].values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rnZfwHhXVx_q"
      },
      "outputs": [],
      "source": [
        "# how does it compare to same months rzsm\n",
        "fig = plt.figure()\n",
        "plt.scatter(m1_df_test['VHI'],m1_df_test['rzsm'].values,color='green',alpha=0.4,s=6)\n",
        "plt.ylabel('observed RZSM')\n",
        "plt.xlabel('observed VHI')\n",
        "#plt.plot(line,line,linestyle='--',color='k')\n",
        "plt.show()\n",
        "print(pearsonr(m1_df_test['VHI'],m1_df_test['rzsm'].values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QEuu6KU6WMYB"
      },
      "outputs": [],
      "source": [
        "# how does it compare to same months rzsm\n",
        "fig = plt.figure()\n",
        "plt.scatter(m1_df_test['vhi-1'],m1_df_test['spei3-1m'].values,color='green',alpha=0.4,s=6)\n",
        "plt.ylabel('observed spei3m')\n",
        "plt.xlabel('observed VHI')\n",
        "#plt.plot(line,line,linestyle='--',color='k')\n",
        "plt.show()\n",
        "print(pearsonr(m1_df_test['vhi-1'],m1_df_test['spei3-1m'].values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0R-ZatLXXZT"
      },
      "source": [
        "Need to detrend and take anomalies for better results from meteorological variables and soil moisture correlation with VHI. Also need to detrend and take VHI as anomaly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9ReygY0ZXWpb"
      },
      "outputs": [],
      "source": [
        "# detrend (if needed and get vars as spatial anomaly)\n",
        "print(m1_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bdcQ-f9YXWvp"
      },
      "outputs": [],
      "source": [
        "def get_anomaly(df,var='VHI'):\n",
        "  dfgc = groupby_gc(df)\n",
        "  # groupby grid cell\n",
        "  for i in range(len(dfgc)):\n",
        "    gc_mean = np.mean(dfgc[i][var])\n",
        "    gc_anom = dfgc[i][var] - gc_mean\n",
        "    dfgc[i][var+' anom'] = gc_anom\n",
        "  return pd.concat(dfgc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cfzOsMECaHlz"
      },
      "outputs": [],
      "source": [
        "m1_df = pd.DataFrame({'lon':vhi_df['lon'].values,'lat':vhi_df['lat'].values,'vhi-1':vhi_df['VHI-1'].values,'precip-1':precip_df['precip-1'].values,'rzsm-1':rzsm_df['rtzsm_inst-1'].values,'spei1-1m':spei1_df['spei1m-1'].values,'spei3-1m':spei3_df['spei3m-1'].values,'spei3':spei3_df['spei3m'].values,'month':vhi_df['month'].values,'year':vhi_df['year'].values,'VHI':vhi_df['VHI'].values,'rzsm':rzsm_df['rtzsm_inst'].values})\n",
        "\n",
        "m1_df_anom = get_anomaly(m1_df)\n",
        "m1_df_anom = get_anomaly(m1_df_anom,'rzsm-1')\n",
        "m1_df_anom = get_anomaly(m1_df_anom,'precip-1')\n",
        "m1_df_anom = get_anomaly(m1_df_anom,'vhi-1')\n",
        "print(m1_df_anom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZPDJJU63aenb"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = plt.figure()\n",
        "plt.scatter(m1_df_anom['VHI anom'].values,m1_df_anom['spei3'].values,color='green',alpha=0.4,s=6)\n",
        "plt.ylabel('observed spei3m')\n",
        "plt.xlabel('observed VHI')\n",
        "#plt.plot(line,line,linestyle='--',color='k')\n",
        "plt.show()\n",
        "print(pearsonr(m1_df_anom['VHI anom'],m1_df_anom['spei3'].values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YlluWKHedLCv"
      },
      "outputs": [],
      "source": [
        "m1_df_test = m1_df_anom[m1_df_anom['year']==2021]\n",
        "m1_df_train = m1_df_anom[m1_df_anom['year']<2021]\n",
        "\n",
        "##\n",
        "trainx = m1_df_train.drop(columns=['VHI','vhi-1','rzsm','precip-1','rzsm-1','VHI anom','spei3'])\n",
        "testx = m1_df_test.drop(columns=['VHI','vhi-1','rzsm','precip-1','rzsm-1','VHI anom','spei3'])\n",
        "# trainy and testy\n",
        "trainy = m1_df_train['VHI anom']\n",
        "testy =  m1_df_test['VHI anom']\n",
        "print(testx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uH_UH7VEeWzU"
      },
      "outputs": [],
      "source": [
        "# Do train / test split by year then predict VHI\n",
        "GBM_model = GradientBoostingRegressor(n_estimators = 200)\n",
        "# fit GBM model to train and test\n",
        "# next fit model using training data\n",
        "GBM_model.fit(trainx,trainy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MCXDfWXSebxn"
      },
      "outputs": [],
      "source": [
        "m_GBM_predictions = GBM_model.predict(testx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4r1tS-fEec8H"
      },
      "outputs": [],
      "source": [
        "line = np.arange(-40,40,1)\n",
        "fig = plt.figure()\n",
        "plt.scatter(testy,m_GBM_predictions,color='green',alpha=0.4,s=6)\n",
        "plt.ylabel('predicted VHI anomaly')\n",
        "plt.xlabel('observed VHI anomaly')\n",
        "plt.plot(line,line,linestyle='--',color='k')\n",
        "plt.show()\n",
        "print(pearsonr(testy,m_GBM_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "skqItjfsfarC"
      },
      "outputs": [],
      "source": [
        "m1_df_test = m1_df_anom[m1_df_anom['year']==2021]\n",
        "m1_df_train = m1_df_anom[m1_df_anom['year']<2021]\n",
        "\n",
        "##\n",
        "trainx = m1_df_train.drop(columns=['VHI','vhi-1','rzsm','precip-1','rzsm-1','VHI anom','spei3','vhi-1 anom'])\n",
        "testx = m1_df_test.drop(columns=['VHI','vhi-1','rzsm','precip-1','rzsm-1','VHI anom','spei3','vhi-1 anom'])\n",
        "# trainy and testy\n",
        "trainy = m1_df_train['VHI anom']\n",
        "testy =  m1_df_test['VHI anom']\n",
        "print(testx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "00atXiDWfsqH"
      },
      "outputs": [],
      "source": [
        "# Do train / test split by year then predict VHI\n",
        "GBM_model = GradientBoostingRegressor(n_estimators = 200)\n",
        "# fit GBM model to train and test\n",
        "# next fit model using training data\n",
        "GBM_model.fit(trainx,trainy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EfIrha8OfweX"
      },
      "outputs": [],
      "source": [
        "m_GBM_predictions = GBM_model.predict(testx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S-JPXV9QfxTs"
      },
      "outputs": [],
      "source": [
        "line = np.arange(-40,40,1)\n",
        "fig = plt.figure()\n",
        "plt.scatter(testy,m_GBM_predictions,color='green',alpha=0.4,s=6)\n",
        "plt.ylabel('predicted VHI anomaly')\n",
        "plt.xlabel('observed VHI anomaly')\n",
        "plt.plot(line,line,linestyle='--',color='k')\n",
        "plt.show()\n",
        "print(pearsonr(testy,m_GBM_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AkIBrmd-gWqI"
      },
      "outputs": [],
      "source": [
        "# now plot observed in same year\n",
        "m1_df_test = m1_df_anom[m1_df_anom['year']==2021]\n",
        "m1_df_train = m1_df_anom[m1_df_anom['year']<2021]\n",
        "#print(m1_df_test)\n",
        "##\n",
        "trainx = m1_df_train.drop(columns=['VHI','vhi-1','precip-1','rzsm-1','VHI anom','vhi-1 anom','spei3-1m','spei1-1m','rzsm-1 anom','precip-1 anom'])\n",
        "testx = m1_df_test.drop(columns=['VHI','vhi-1','precip-1','rzsm-1','VHI anom','vhi-1 anom','spei3-1m','spei1-1m','rzsm-1 anom','precip-1 anom'])\n",
        "# trainy and testy\n",
        "trainy = m1_df_train['VHI anom']\n",
        "testy =  m1_df_test['VHI anom']\n",
        "print(trainx)\n",
        "print(testx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BpRvsstWh-40"
      },
      "outputs": [],
      "source": [
        "# Do train / test split by year then predict VHI\n",
        "GBM_model = GradientBoostingRegressor(n_estimators = 200)\n",
        "# fit GBM model to train and test\n",
        "# next fit model using training data\n",
        "GBM_model.fit(trainx,trainy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u2-SNAF6iCdV"
      },
      "outputs": [],
      "source": [
        "m_GBM_predictions = GBM_model.predict(testx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_AWZ3tXHiGCe"
      },
      "outputs": [],
      "source": [
        "line = np.arange(-40,40,1)\n",
        "fig = plt.figure()\n",
        "plt.scatter(testy,m_GBM_predictions,color='green',alpha=0.4,s=6)\n",
        "plt.ylabel('predicted VHI anomaly')\n",
        "plt.xlabel('observed VHI anomaly')\n",
        "plt.plot(line,line,linestyle='--',color='k')\n",
        "plt.show()\n",
        "print(pearsonr(testy,m_GBM_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pAfhj-RGTHR-"
      },
      "outputs": [],
      "source": [
        "print(m1_df_anom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "udLtN2RVTHw1"
      },
      "outputs": [],
      "source": [
        "# get average rzsm, vhi, spei etc per grid cell\n",
        "m1_df_anom_gc_list = groupby_gc(m1_df_anom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IbOO7sWTAAJm"
      },
      "outputs": [],
      "source": [
        "# fuction for correlations and averages for each grid cell\n",
        "def per_gc_metrics(df):\n",
        "  m1_df_anom_gc_list = groupby_gc(df)\n",
        "  lat_list=[]\n",
        "  lon_list=[]\n",
        "  vhi_averages=[]\n",
        "  vhi_spei3_ccoefs=[]\n",
        "  vhi_rzsm_ccoefs=[]\n",
        "  for i in range(len(m1_df_anom_gc_list)):\n",
        "    # get average vhi and plot\n",
        "    vhi_averages.append(np.mean(m1_df_anom_gc_list[i]['VHI']))\n",
        "    vhi_spei3_ccoefs.append(pearsonr(m1_df_anom_gc_list[i]['VHI'],m1_df_anom_gc_list[i]['spei3'])[0])\n",
        "    vhi_rzsm_ccoefs.append(pearsonr(m1_df_anom_gc_list[i]['VHI'],m1_df_anom_gc_list[i]['rzsm'])[0])\n",
        "    # get latitude and longitude coordinates\n",
        "    lat = m1_df_anom_gc_list[i]['lat'].values[0]\n",
        "    lat_list.append(lat)\n",
        "    lon = m1_df_anom_gc_list[i]['lon'].values[0]\n",
        "    lon_list.append(lon)\n",
        "  return lat_list, lon_list, vhi_averages, vhi_spei3_ccoefs, vhi_rzsm_ccoefs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OxZOaaY5Gjts"
      },
      "outputs": [],
      "source": [
        "lat_list, lon_list, vhi_avs, vhi_spei3_ccoefs, vhi_rzsm_ccoefs = per_gc_metrics(m1_df_anom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Z2lFQHhdGyEE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0qLNO3UPGWRV"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10,12))\n",
        "ax1 = fig.add_subplot(1,1,1,projection=ccrs.PlateCarree())\n",
        "#ax1.coastlines()\n",
        "im=ax1.scatter(lon_list, lat_list, c=vhi_avs, marker=',', transform=ccrs.PlateCarree(), cmap='Spectral',vmin=0,vmax=70)\n",
        "# # Set the location and size of the colorbar axes manually\n",
        "#cax = fig.add_axes([]) # left, bottom, width, height\n",
        "# # Add the colorbar\n",
        "divider = make_axes_locatable(ax1)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05,axes_class=plt.Axes)\n",
        "cbar = fig.colorbar(im, ax=ax1,cax=cax)\n",
        "cbar.ax.set_ylabel('average VHI',fontsize='14')\n",
        "ax1.title.set_text('Average VHI (2021)')\n",
        "ax1.set_extent([-80, -30, -40, 10], crs=ccrs.PlateCarree())\n",
        "#plt.savefig('plots/Iizumi_2020_maize_global.pdf')\n",
        "#ax1.add_feature(cf.BORDERS)\n",
        "ax1.add_feature(shape_feature)\n",
        "ax1.add_feature(cf.LAND)\n",
        "ax1.add_feature(cf.OCEAN)\n",
        "ax1.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RsfLUrAdIbDQ"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10,12))\n",
        "ax1 = fig.add_subplot(1,1,1,projection=ccrs.PlateCarree())\n",
        "#ax1.coastlines()\n",
        "im=ax1.scatter(lon_list, lat_list, c=vhi_spei3_ccoefs, marker=',', transform=ccrs.PlateCarree(), cmap='Spectral')\n",
        "# # Set the location and size of the colorbar axes manually\n",
        "#cax = fig.add_axes([]) # left, bottom, width, height\n",
        "# # Add the colorbar\n",
        "divider = make_axes_locatable(ax1)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05,axes_class=plt.Axes)\n",
        "cbar = fig.colorbar(im, ax=ax1,cax=cax)\n",
        "cbar.ax.set_ylabel('correlation coefficient',fontsize='14')\n",
        "ax1.title.set_text('correlation between spei3 and vhi')\n",
        "ax1.set_extent([-80, -30, -40, 10], crs=ccrs.PlateCarree())\n",
        "#plt.savefig('plots/Iizumi_2020_maize_global.pdf')\n",
        "#ax1.add_feature(cf.BORDERS)\n",
        "ax1.add_feature(shape_feature)\n",
        "ax1.add_feature(cf.LAND)\n",
        "ax1.add_feature(cf.OCEAN)\n",
        "ax1.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T3sEA03fNG6Y"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10,12))\n",
        "ax1 = fig.add_subplot(1,1,1,projection=ccrs.PlateCarree())\n",
        "#ax1.coastlines()\n",
        "im=ax1.scatter(lon_list, lat_list, c=vhi_rzsm_ccoefs, marker=',', transform=ccrs.PlateCarree(), cmap='Spectral')\n",
        "# # Set the location and size of the colorbar axes manually\n",
        "#cax = fig.add_axes([]) # left, bottom, width, height\n",
        "# # Add the colorbar\n",
        "divider = make_axes_locatable(ax1)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05,axes_class=plt.Axes)\n",
        "cbar = fig.colorbar(im, ax=ax1,cax=cax)\n",
        "cbar.ax.set_ylabel('correlation coefficient',fontsize='14')\n",
        "ax1.title.set_text('correlation between rzsm and vhi')\n",
        "ax1.set_extent([-80, -30, -40, 10], crs=ccrs.PlateCarree())\n",
        "#plt.savefig('plots/Iizumi_2020_maize_global.pdf')\n",
        "#ax1.add_feature(cf.BORDERS)\n",
        "ax1.add_feature(shape_feature)\n",
        "ax1.add_feature(cf.LAND)\n",
        "ax1.add_feature(cf.OCEAN)\n",
        "ax1.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TWCY9fC4TH3C"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(m1_df_anom_gc_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BTcDyY29E-Av"
      },
      "outputs": [],
      "source": [
        "#### Forward months\n",
        "\n",
        "# create a function to match variable with previous month\n",
        "### This will be a Figure for the paper\n",
        "def match_month_forward(df,var_name='VHI',months_plus=1):\n",
        "  # match each month with previus month(s) to find correlation between them\n",
        "  # first need to split into list of dfs based on grid cell location\n",
        "  # also need to create an if statement to only do if -1 is above February 2003\n",
        "  # append nan for this case\n",
        "  # and need to create an if statement for Jan 2004-2021 which gets December the previous year instead\n",
        "  # dont need to do this as already accounted for in df ordering\n",
        "  # Changed function to give future rather than past months.\n",
        "  # Need to check if this works properly\n",
        "\n",
        "  # Need to use if statement to cut off last part\n",
        "\n",
        "  df_list = groupby_gc(df)\n",
        "  #print(df_list[0])\n",
        "  dfi_list=[]\n",
        "  for i in range(len(df_list)):\n",
        "    dfi = df_list[i]\n",
        "    dfi.reset_index(inplace=True)\n",
        "    dims = dfi.shape\n",
        "    #print(dfi.shape)\n",
        "    pm_var_list=[]\n",
        "    #print(dfi)\n",
        "    for j in np.arange(dims[0]):\n",
        "      if var_name == 'VHI':\n",
        "        if j >= months_plus:\n",
        "          pm_var_list.append(dfi.iloc[j+months_plus,3])\n",
        "        else:\n",
        "           pm_var_list.append(np.nan)\n",
        "      elif var_name == 'precip':\n",
        "        if j >= months_plus:\n",
        "          pm_var_list.append(dfi.iloc[j+months_plus,6])\n",
        "        else:\n",
        "           pm_var_list.append(np.nan)\n",
        "      elif var_name == 'rtzsm_inst':\n",
        "        if j >= months_plus:\n",
        "          pm_var_list.append(dfi.iloc[j+months_plus,7])\n",
        "        else:\n",
        "           pm_var_list.append(np.nan)\n",
        "      elif var_name == 'spei1m':\n",
        "        if j >= months_plus:\n",
        "          pm_var_list.append(dfi.iloc[j+months_plus,8])\n",
        "        else:\n",
        "           pm_var_list.append(np.nan)\n",
        "      elif var_name == 'spei3m':\n",
        "        if j >= months_plus:\n",
        "          pm_var_list.append(dfi.iloc[j+months_plus,9])\n",
        "        else:\n",
        "           pm_var_list.append(np.nan)\n",
        "    #print(pm_var_list)\n",
        "    dfi[var_name+str(+months_plus)] = pm_var_list\n",
        "    #print(dfi)\n",
        "    dfi_list.append(dfi)\n",
        "  return pd.concat(dfi_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FnqJk6w3HmT7"
      },
      "outputs": [],
      "source": [
        "#\n",
        "#df_soy_nm = match_month_forward(df_soy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uD3oPlovk6rM"
      },
      "outputs": [],
      "source": [
        "# fit selection of simple ML models, show model evaluation broken down by region and (if time) cluster of correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-cSeR5e1mqfJ"
      },
      "outputs": [],
      "source": [
        "df_crops2=pd.concat(m1_df_anom_gc_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-bVWPhKFm64n"
      },
      "outputs": [],
      "source": [
        "print(df_crops2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D60Qp31hm-Fi"
      },
      "outputs": [],
      "source": [
        "# Get train and test and select features\n",
        "features_df_vhi = pd.DataFrame({'lat':df_crops2['lat'],'lon':df_crops2['lon'],'rzsm':df_crops2['rzsm-1'],'spei3':df_crops2['spei3-1m'],'spei1':df_crops2['spei1-1m'],'precip':df_crops2['precip-1 anom'],'month':df_crops2['month'],'year':df_crops2['year'],\n",
        "                                'vhi':df_crops2['VHI']})\n",
        "\n",
        "features_df_vhi_anom = pd.DataFrame({'lat':df_crops2['lat'],'lon':df_crops2['lon'],'rzsm':df_crops2['rzsm-1'],'spei3':df_crops2['spei3-1m'],'spei1':df_crops2['spei1-1m'],'precip':df_crops2['precip-1 anom'],'month':df_crops2['month'],'year':df_crops2['year'],\n",
        "                                'vhi':df_crops2['VHI anom']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EHm3MnXS8KYb"
      },
      "outputs": [],
      "source": [
        "#create train/test splits\n",
        "# select 3 random years\n",
        "yrs_to_sample = np.arange(2003,2021+1)\n",
        "print(yrs_to_sample)\n",
        "sample_yrs =np.random.choice(yrs_to_sample,5)\n",
        "print(sample_yrs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YKMI58H389io"
      },
      "outputs": [],
      "source": [
        "# Get 5 sets of training and testing sets\n",
        "def train_test_splits(features_df,sample_yrs):\n",
        "  train_set_list=[]\n",
        "  test_set_list=[]\n",
        "  for i in range(len(sample_yrs)):\n",
        "    train_seti = features_df[features_df['year']!=sample_yrs[i]]\n",
        "    test_seti = features_df[features_df['year']==sample_yrs[i]]\n",
        "    train_set_list.append(train_seti)\n",
        "    test_set_list.append(test_seti)\n",
        "  return train_set_list,test_set_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1qsBTQ75AvLh"
      },
      "outputs": [],
      "source": [
        "train_sets, test_sets = train_test_splits(features_df_vhi,sample_yrs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OzSoECT8BRd7"
      },
      "outputs": [],
      "source": [
        "def fit_gbm_splits(trains, tests,target_var):\n",
        "  predictions_list=[]\n",
        "  for i in range(len(trains)):\n",
        "    trainxi = trains[i].drop(columns=[target_var])\n",
        "    testxi =  tests[i].drop(columns=[target_var])\n",
        "    # Get y data\n",
        "    trainyi = trains[i][target_var]\n",
        "    testyi = tests[i][target_var]\n",
        "    #\n",
        "    GBM_model = GradientBoostingRegressor(n_estimators=200)\n",
        "    GBM_model.fit(trainxi,trainyi)\n",
        "    print('model: ',i,' trained')\n",
        "    ## Return set of predictions for each by GBM model\n",
        "    predictionsi = GBM_model.predict(testxi)\n",
        "    predictions_list.append(predictionsi)\n",
        "  return predictions_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9f4INKteFPda"
      },
      "outputs": [],
      "source": [
        "#gbm_predictions = fit_gbm_splits(train_sets,test_sets,target_var='vhi')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfL6GZIE8UMs"
      },
      "source": [
        "Train model and then evaluate based on region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IwlpLeDK8TEj"
      },
      "outputs": [],
      "source": [
        "# save GBM model predictions\n",
        "def make_output(test_sets,test_yrs,gbm_predictions):\n",
        "  gbm_output=[]\n",
        "  for i in range(len(gbm_predictions)):\n",
        "    gbmpi = gbm_predictions[i]\n",
        "    testyr_list = [test_yrs[i]]*len(gbmpi)\n",
        "    test_sets[i]['test year'] = testyr_list\n",
        "    test_sets[i]['predictions'] = gbmpi\n",
        "    test_sets[i]['model run'] = [i]*len(gbmpi)\n",
        "    gbm_output.append(test_sets[i])\n",
        "\n",
        "  return pd.concat(gbm_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y0BkZamJSxJi"
      },
      "outputs": [],
      "source": [
        "#gbmOutput = make_output(test_sets,sample_yrs,gbm_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "erNg3A19TICD"
      },
      "outputs": [],
      "source": [
        "#print(gbmOutput)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FS9mZrlNTIcz"
      },
      "outputs": [],
      "source": [
        "# save dataframe\n",
        "#gbmOutput.to_csv('/content/drive/MyDrive/GBM_model_output.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g6dV5FNXG46k"
      },
      "outputs": [],
      "source": [
        "def fit_rfr_splits(trains, tests,target_var):\n",
        "  predictions_list=[]\n",
        "  for i in range(len(trains)):\n",
        "    trainxi = trains[i].drop(columns=[target_var])\n",
        "    testxi =  tests[i].drop(columns=[target_var])\n",
        "    # Get y data\n",
        "    trainyi = trains[i][target_var]\n",
        "    testyi = tests[i][target_var]\n",
        "    #\n",
        "    GBM_model = RandomForestRegressor(n_estimators=100)\n",
        "    GBM_model.fit(trainxi,trainyi)\n",
        "    print('model: ',i,' trained')\n",
        "    ## Return set of predictions for each by GBM model\n",
        "    predictionsi = GBM_model.predict(testxi)\n",
        "    predictions_list.append(predictionsi)\n",
        "  return predictions_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XmIem7A4JmEr"
      },
      "outputs": [],
      "source": [
        "# Need to keep test years the same as initial GBM model run for comparison\n",
        "sample_yrs = [2019, 2008, 2017, 2003, 2012]\n",
        "train_sets, test_sets = train_test_splits(features_df_vhi,sample_yrs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gySTUldyHHHY"
      },
      "outputs": [],
      "source": [
        "rfr_predictions = fit_rfr_splits(train_sets,test_sets,target_var='vhi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8lyUzs1AHMhK"
      },
      "outputs": [],
      "source": [
        "rfrOutput = make_output(test_sets,sample_yrs,rfr_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7m-eIF8OMC1S"
      },
      "outputs": [],
      "source": [
        "rfrOutput.to_csv('/content/drive/MyDrive/rfr_model_output.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WqT62l3dcltQ"
      },
      "outputs": [],
      "source": [
        "# Do linear regression\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "def fit_mlr_splits(trains, tests,target_var):\n",
        "  predictions_list=[]\n",
        "  for i in range(len(trains)):\n",
        "    trainxi = trains[i].drop(columns=[target_var])\n",
        "    testxi =  tests[i].drop(columns=[target_var])\n",
        "    # Get y data\n",
        "    trainyi = trains[i][target_var]\n",
        "    testyi = tests[i][target_var]\n",
        "    #\n",
        "    GBM_model = LinearRegression()\n",
        "    scaler = RobustScaler()\n",
        "    trainxi = scaler.fit_transform(trainxi)\n",
        "    GBM_model.fit(trainxi,trainyi)\n",
        "    print('model: ',i,' trained')\n",
        "    ## Return set of predictions for each by GBM model\n",
        "    print(testxi)\n",
        "    testxi = scaler.fit_transform(testxi)\n",
        "    print(testxi)\n",
        "    predictionsi = GBM_model.predict(testxi)\n",
        "    predictions_list.append(predictionsi)\n",
        "  return predictions_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ObttKoDJd2JJ"
      },
      "outputs": [],
      "source": [
        "train_sets, test_sets = train_test_splits(features_df_vhi,sample_yrs)\n",
        "mlr_predictions = fit_mlr_splits(train_sets,test_sets,target_var='vhi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "56JpJYk2eEl7"
      },
      "outputs": [],
      "source": [
        "mlrOutput = make_output(test_sets,sample_yrs,mlr_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "P7mHH2w4eIbr"
      },
      "outputs": [],
      "source": [
        "mlrOutput.to_csv('/content/drive/MyDrive/mlr_model_output.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0IwSYPf7eXPt"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HAbakp_VeTGB"
      },
      "outputs": [],
      "source": [
        "def fit_svr_splits(trains, tests,target_var):\n",
        "  predictions_list=[]\n",
        "  for i in range(len(trains)):\n",
        "    trainxi = trains[i].drop(columns=[target_var])\n",
        "    testxi =  tests[i].drop(columns=[target_var])\n",
        "    # Get y data\n",
        "    trainyi = trains[i][target_var]\n",
        "    testyi = tests[i][target_var]\n",
        "    #\n",
        "    GBM_model = SVR()\n",
        "    scaler = RobustScaler()\n",
        "    trainxi = scaler.fit_transform(trainxi)\n",
        "    GBM_model.fit(trainxi,trainyi)\n",
        "    print('model: ',i,' trained')\n",
        "    ## Return set of predictions for each by GBM model\n",
        "    testxi = scaler.fit_transform(testxi)\n",
        "    predictionsi = GBM_model.predict(testxi)\n",
        "    predictions_list.append(predictionsi)\n",
        "  return predictions_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sntPhFCXeujF"
      },
      "outputs": [],
      "source": [
        "train_sets, test_sets = train_test_splits(features_df_vhi,sample_yrs)\n",
        "svr_predictions = fit_svr_splits(train_sets,test_sets,target_var='vhi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LqcDsb0MezlT"
      },
      "outputs": [],
      "source": [
        "svrOutput = make_output(test_sets,sample_yrs,svr_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lJ6-uBBSe5Z9"
      },
      "outputs": [],
      "source": [
        "svrOutput.to_csv('/content/drive/MyDrive/svr_model_output.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Le4v4Cfgko_M"
      },
      "outputs": [],
      "source": [
        "# bring in code for dense neural network\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qRvoJdqomw0E"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(784,)) # start neural network with input node with shape containing features\n",
        "dense = layers.Dense(64, activation=\"relu\")\n",
        "x = dense(inputs)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(10)(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X15N9PlQm9cs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1BN4rnrKPAHUengjYu0bSwJp-WHpJnQQ2",
      "authorship_tag": "ABX9TyNkqVGdL+1fNKuwsP4qXVJH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}